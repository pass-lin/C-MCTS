# C-MCTS项目官方开源代码指南
[English Document](README_EN.md)
## 项目概述

本项目实现了论文[《Leveraging Constrained Monte Carlo Tree Search to Generate Reliable Long Chain-of-Thought for Mathematical Reasoning》](https://arxiv.org/abs/2502.11169 )中提出的C-MCTS算法。该项目旨在通过约束蒙特卡洛树搜索提高大型语言模型的数学推理能力，特别是生成可靠的长思维链。

## 代码结构
### COT测试方法
COT的baseline请使用[Qwen的仓库](https://github.com/QwenLM/Qwen2.5-Math )运行脚本以达到最好的效果

### 数据集
所有使用的数据集位于`data`目录下，涵盖多个数学推理基准测试，包括但不限于GSM8K、Math500、AquA等。

### 测试脚本
测试脚本位于`examples`目录下，每个数据集对应一个子目录，包含针对该数据集的评估脚本。

## 以AquA数据集为例的文件说明

### `examples/AquA/eval_aqua_cot.py`
- **用途**：评估COT（Chain-of-Thought）基线模型。
- **细节**：在某些情况下，我们的答案提取方法可能比Qwen的效果更好。此时，我们会使用我们的方法作为最终答案。

### `examples/AquA/run_chatmcts_aqua_PRM.py`
- **用途**：运行[RAP-MCTS基线](https://arxiv.org/abs/2305.14992 )。
- **细节**：我们对原始的prompt进行了修改，并改成了对话形式。这比使用原始方法的效果要好得多。

### `examples/AquA/run_chatmcts_aqua_PRM.py`（带PRM版本）
- **用途**：与上述脚本类似，但加入了PRM（Process Reward Model）。

### `examples/AquA/run_cot_aqua.py`
- **用途**：使用与我们方法相同的参数生成多个COT，然后通过投票法选择答案。

### `examples/AquA/run_deepmcts_aqua.py`
- **用途**：我们的C-MCTS方法。
- **细节**：大部分实现与论文中介绍的一致。在测试过程中可能会输出各种各样的准确率，但只有`max_reward_path_acc`会被作为实验结果。

## 参数调整

以下是需要调整的关键参数：

```python
partial_order = [
    True,
    True,
    False,
    True,
    False,
]  # 启动哪条偏序规则，不使用就全部选False
native_rewards_mode = True  # 是否使用自身作为PRM
# 没有PRM的情况下，需要更多规则限制，所以全开。当然你也可以全关
if native_rewards_mode:
    partial_order = [True, True, True, True, True]
```

### 参数说明
- `partial_order`：控制是否启用特定的偏序规则。如果不需要，可以全部设置为`False`。
- `native_rewards_mode`：决定是否使用模型自身作为PRM（过程奖励模型）。启用此模式时，在大部分脚本里会自动开启所有偏序规则，少部分脚本里会保持和使用PRM模型时保持一致

## 实验结果
需要注意的是，这个仓库里的代码和论文里的代码是有点不一样的。经过调试和修改后我们发现plan集对效果并不好，所有在这个仓库里去掉了plan集。另外还有些细节的调整，原始论文里所有脚本都是启动全部偏序规则的，在这里则是选择性启动

### 主实验表格
主要的实验结果，会发现我们的效果可以超过72B模型，并且RULE可以进一步提升效果。而且可以注意到的是即使没有PRM依赖rule也可以达到和72B接近的效果

| 数据集           | qwen25-it-cot-7B | qwen25-it-cot-72B | qwen25-it-maj-7B | C-MCTS | C-MCTS+RULE | C-MCTS+RULE-wo-PRM |
|:-----------------|:-----------------|:------------------|:-----------------|:-------|:------------|:-------------------|
| gaokao2023en      | 66.0             | 73.2              | 69.0             | 75.8   | 76.6        | 71.1             |
| MATH-500          | 77.0             | 83.4              | 79.6             | 84.6   | 85.4        | 79.2              |
| AauA              | 74.4             | 79.2              | 81.1             | 86.2   | 87.7        | 85.4               |
| svamp             | 93.9             | 95.4              | 93.5             | 95.9   | 96.4        | 95.3               |
| GSM8K             | 92.4             | 95.8              | 93.0             | 95.1   | 95.4        | 92.7               |
| cmath             | 89.7             | 93.0              | 93.1             | 94.3   | 95.0        | 92.5               |
| cn_middle_school  | 70.2             | 83.1              | 82.1             | 87.1   | 87.1        | 83.1               |
| gaokao_math_qa    | 60.9             | 74.3              | 68.6             | 78.9   | 80.3        | 72.6               |
| weak12k           | 85.6             | 91.3              | 90.0             | 92.5   | 93.1        | 88.5               |
| **平均值**        | 78.9             | 85.4              | 83.3             | 87.8   | 88.5        | 84.7               |

### 和RAP-MCTS的比较

下面是和RAP-MCTS的比较，发现加了PRM爆杀，但没有PRM不如人家。说明PRM对我们目前这个工作是很重要的，并且RAM-MCTS有没有PRM效果都差不多。说明原始的RAP生成的不同action没啥大的区别，所以用不用PRM也就没什么大区别

| 数据集           | gaokao2023en | MATH-500 | AauA | svamp | GSM8K | cmath | cn_middle_school | gaokao_math_qa | weak12k | avg  |
|:-----------------|:-------------|:---------|:-----|:------|:------|:------|:-----------------|:---------------|:--------|:-----|
| C-MCTS           | 75.8         | 84.6     | 86.2 | 95.9  | 95.1  | 94.3  | 87.1            | 78.9           | 92.5    | 87.8 |
| C-MCTS-wo-PRM    | 68.8         | 77.0     | 80.7 | 95.8  | 92.7  | 93.0  | 75.2            | 70.3           | 88.2    | 82.4 |
| RAP-mcts      | 67.5         | 75.0     | 84.7 | 93.0  | 92.5  | 93.0  | 83.1            | 72.0           | 89.5    | 83.3 |
| RAP-mcts+PRM  | 69.8         | 77.2     | 83.7 | 93.5  | 92.5  | 93.3  | 83.1            | 72.6           | 89.3    | 83.8 |

### 消融实验


这部分我们把数据集分成了两部分。大于90分的简单数据集我们分到一个表格，其他的分到一个表格

#### 困难数据集实验结果 

| 方法                   | gaokao2023en | MATH-500 | AauA | cn_middle_school | gaokao_math_qa | avg  |
|:-----------------------|:-------------|:---------|:-----|:-----------------|:---------------|:-----|
| C-MCTS-wo-PRM          | 68.8         | 77.0     | 80.7 | 75.2            | 70.3           | 74.4 |
| C-MCTS-wo-Reflect-code | 74.0         | 82.4     | 85.0 | 86.1            | 76.9           | 80.8 |
| C-MCTS-wo-Reflect      | 74.8         | 83.8     | 84.6 | 86.1            | 78.3           | 81.5 |
| C-MCTS                 | 75.8         | 84.6     | 86.2 | 87.1            | 78.9           | 82.5 |
#### 简单数据集实验结果 

| 方法                   | svamp | GSM8K | cmath | weak12k | avg  |
|:-----------------------|:------|:------|:------|:--------|:-----|
| C-MCTS-wo-PRM          | 95.8  | 92.7  | 93.0  | 88.2    | 92.4 |
| C-MCTS-wo-Reflect-code | 96.0  | 95.2  | 94.5  | 92.6    | 94.5 |
| C-MCTS-wo-Reflect      | 96.2  | 95.1  | 94.6  | 92.6    | 94.6 |
| C-MCTS                 | 95.9  | 95.1  | 94.3  | 92.5    | 94.4 |

我们可以发现，在简单数据集上不同的动作集少了哪个都没什么区别。但是在困难数据集上，每添加一个动作集都可以一定程度提升模型性能。而且我们发现即使只有understand数据集也可以达到很好的效果。

并且不管是简单还是困难数据集上，少了PRM对模型效果都是很大的性能损失。
